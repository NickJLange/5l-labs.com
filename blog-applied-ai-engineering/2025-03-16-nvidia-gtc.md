---
slug: nvdia-gtc
title: Off to Nvidia GTC
authors: [njl]
tags: [blog, nvidia, ai, gpu, deep-learning, machine-learning]
description: Exploring the privacy landscape at NVIDIA GTC 2025, with a focus on Distributed Training and Private LLMs.
embedding_url: /embeddings/applied-ai-engineering/nvdia-gtc.embedding.json
---

<!-- truncate -->
Going to California for NVIDIA GTC 2025, what are the areas of focus for privacy?

### Focus Areas

- **Distributed Training**: How can we train large models across multiple nodes while maintaining data isolation?
- **Private LLMs**: Exploring the latest in quantization (FP8/FP4) and local inference to keep enterprise data on-premise.
- **NVIDIA Confidential Computing**: Investigating H100/B200 support for hardware-level isolation.

We'll be looking for sessions that bridge the gap between massive compute and strict data sovereignty. Stay tuned for the recap!

<!-- *This post was cleaned up with Automation to clarify thoughts for the reader.* -->
